{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:15.845429Z",
     "start_time": "2018-05-15T01:10:15.836712Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "# Import tree stuff:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import patsy as patsy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import other models:\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Bagging:\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Searching hyperparameters and cross-validating\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:16.746927Z",
     "start_time": "2018-05-15T01:10:16.261116Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"x_liv.pkl\", 'rb') as picklefile: \n",
    "    x_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"y_liv.pkl\", 'rb') as picklefile: \n",
    "    y_liv = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:18.246084Z",
     "start_time": "2018-05-15T01:10:16.748794Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"y_train_liv.pkl\", 'rb') as picklefile: \n",
    "    y_train_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"y_test_liv.pkl\", 'rb') as picklefile: \n",
    "    y_test_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"x_train_liv.pkl\", 'rb') as picklefile: \n",
    "    x_train_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"x_test_liv.pkl\", 'rb') as picklefile: \n",
    "    x_test_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"x_train_scaled_liv.pkl\", 'rb') as picklefile: \n",
    "    x_train_scaled_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"x_test_scaled_liv.pkl\", 'rb') as picklefile: \n",
    "    x_test_scaled_liv = pickle.load(picklefile)\n",
    "    \n",
    "with open(\"x_scaled_liv.pkl\", 'rb') as picklefile: \n",
    "    x_scaled_liv = pickle.load(picklefile)\n",
    "\n",
    "with open(\"patientdataICD9_liv.pkl\", 'rb') as picklefile: \n",
    "    patientdataICD9_liv = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:18.722307Z",
     "start_time": "2018-05-15T01:10:18.699772Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train_liv\n",
    "y_train = y_train_liv\n",
    "x_test = x_test_liv\n",
    "y_test = y_test_liv\n",
    "x = x_liv\n",
    "y = y_liv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:22.826509Z",
     "start_time": "2018-05-15T01:10:22.691523Z"
    }
   },
   "outputs": [],
   "source": [
    "y = y.str.replace('>30','NO')\n",
    "y_test = y_test.str.replace('>30','NO')\n",
    "y_train = y_train.str.replace('>30','NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:22.921229Z",
     "start_time": "2018-05-15T01:10:22.915151Z"
    }
   },
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:23.713455Z",
     "start_time": "2018-05-15T01:10:23.554707Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:03:42.871274Z",
     "start_time": "2018-05-15T01:03:42.853309Z"
    }
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T18:30:00.674495Z",
     "start_time": "2018-05-14T18:30:00.670838Z"
    }
   },
   "outputs": [],
   "source": [
    "def quick_test(model, X, y):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    return model.score(xtest, ytest)\n",
    "\n",
    "def quick_test_afew_times(model, X, y, n=10):\n",
    "    return np.mean([quick_test(model, X, y) for j in range(n)])\n",
    "\n",
    "#linearsvc = LinearSVC()\n",
    "# Do the test 10 times with a LinearSVC and get the average score\n",
    "#quick_test_afew_times(linearsvc, X, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree and random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T18:30:10.935853Z",
     "start_time": "2018-05-14T18:30:01.726722Z"
    }
   },
   "outputs": [],
   "source": [
    "decisiontree = DecisionTreeClassifier(max_depth=2)\n",
    "quick_test_afew_times(decisiontree, x, y)\n",
    "\n",
    "# using x train and x test with x that had been scaled before test-train split:\n",
    "# 0.5664330167048804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T18:30:41.745670Z",
     "start_time": "2018-05-14T18:30:13.302400Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier()\n",
    "quick_test_afew_times(randomforest, x, y)\n",
    "\n",
    "# using x train and x test with x that had been scaled before test-train split:\n",
    "# 0.5488994431706519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T18:31:40.230937Z",
     "start_time": "2018-05-14T18:31:36.770283Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train, y_train)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T01:12:13.295942Z",
     "start_time": "2018-05-10T01:12:13.293423Z"
    }
   },
   "source": [
    "#### SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:11:09.507364Z",
     "start_time": "2018-05-11T02:11:02.928321Z"
    }
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:11:09.651741Z",
     "start_time": "2018-05-11T02:11:09.509343Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:11:09.916248Z",
     "start_time": "2018-05-11T02:11:09.653816Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(y_train_smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:11:15.216638Z",
     "start_time": "2018-05-11T02:11:09.917992Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train_smote, y_train_smote)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:32:19.512790Z",
     "start_time": "2018-05-11T02:30:54.285438Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=200, min_samples_split=10)\n",
    "randomforest.fit(x_train_smote, y_train_smote)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Undersampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:03:51.691806Z",
     "start_time": "2018-05-15T01:03:51.462279Z"
    }
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "x_train_undersampled, y_train_undersampled = rus.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:03:51.914960Z",
     "start_time": "2018-05-15T01:03:51.816228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(y_train_undersampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:03.723763Z",
     "start_time": "2018-05-15T01:03:52.413721Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=200)\n",
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T19:28:25.953821Z",
     "start_time": "2018-05-14T19:28:15.523287Z"
    }
   },
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "class_weights['NO'] = 1\n",
    "class_weights['<30'] = 0.15\n",
    "randomforest = RandomForestClassifier(n_estimators=200, class_weight = class_weights, min_samples_split=10)\n",
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T18:57:07.456989Z",
     "start_time": "2018-05-14T18:56:57.948612Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=200, min_samples_split=10)\n",
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T19:05:51.062105Z",
     "start_time": "2018-05-14T19:05:50.002474Z"
    }
   },
   "outputs": [],
   "source": [
    "model = randomforest\n",
    "y_pred_proba = model.predict_proba(x_test)\n",
    "y_pred = y_pred_proba >= 0.25 #(this is the value to play around with)\n",
    "#y_pred\n",
    "#print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "#metrics.confusion_matrix(y_test, y_pred)\n",
    "#plot prec and recall by threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:05:06.545194Z",
     "start_time": "2018-05-11T02:04:57.943722Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=200, min_samples_split=20)\n",
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T18:06:49.685164Z",
     "start_time": "2018-05-10T18:06:49.675374Z"
    }
   },
   "source": [
    "#### Extra-random trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:06:00.704523Z",
     "start_time": "2018-05-11T02:05:48.269750Z"
    }
   },
   "outputs": [],
   "source": [
    "extraforest = ExtraTreesClassifier(n_estimators=200, min_samples_split=10)\n",
    "extraforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "extraforest.score(x_test, y_test)\n",
    "y_pred = extraforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:08:25.792478Z",
     "start_time": "2018-05-11T02:06:00.706545Z"
    }
   },
   "outputs": [],
   "source": [
    "extraforest = ExtraTreesClassifier(n_estimators=2000)\n",
    "extraforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "extraforest.score(x_test, y_test)\n",
    "y_pred = extraforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimator in range(100, 2000, 100):\n",
    "    extraforest = ExtraTreesClassifier(n_estimators=n_estimator)\n",
    "    extraforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "    extraforest.score(x_test, y_test)\n",
    "    y_pred = extraforest.predict(x_test)\n",
    "    print(\"Number of estimators: %.3f\"% n_estimator)\n",
    "    print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosted trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:10:45.838495Z",
     "start_time": "2018-05-11T02:09:12.790114Z"
    }
   },
   "outputs": [],
   "source": [
    "# boosted no resampling\n",
    "\n",
    "boostforest = AdaBoostClassifier(n_estimators=200)\n",
    "boostforest.fit(x_train, y_train)\n",
    "boostforest.score(x_test, y_test)\n",
    "y_pred = boostforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:11:02.926533Z",
     "start_time": "2018-05-11T02:10:45.842730Z"
    }
   },
   "outputs": [],
   "source": [
    "# boosted undersampled\n",
    "\n",
    "boostforest = AdaBoostClassifier(n_estimators=200)\n",
    "boostforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "boostforest.score(x_test, y_test)\n",
    "y_pred = boostforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T17:48:21.193570Z",
     "start_time": "2018-05-10T17:43:46.625127Z"
    }
   },
   "outputs": [],
   "source": [
    "# boosted undersampled\n",
    "\n",
    "boostforest = AdaBoostClassifier(n_estimators=2000)\n",
    "boostforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "boostforest.score(x_test, y_test)\n",
    "y_pred = boostforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T02:46:28.520028Z",
     "start_time": "2018-05-11T02:42:59.282749Z"
    }
   },
   "outputs": [],
   "source": [
    "# boosted SMOTE\n",
    "\n",
    "boostforest = AdaBoostClassifier(n_estimators=200)\n",
    "boostforest.fit(x_train_smote, y_train_smote)\n",
    "boostforest.score(x_test, y_test)\n",
    "y_pred = boostforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:13.472320Z",
     "start_time": "2018-05-15T01:04:04.253794Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=200, min_samples_split=10)\n",
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:13.511596Z",
     "start_time": "2018-05-15T01:04:13.474052Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:13.538402Z",
     "start_time": "2018-05-15T01:04:13.513356Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance = list(zip(x_train.columns, randomforest.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:13.542681Z",
     "start_time": "2018-05-15T01:04:13.540312Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_by_second = sorted(feature_importance, key=lambda tup: tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:14.686347Z",
     "start_time": "2018-05-15T01:04:14.681692Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_by_second[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:19.189600Z",
     "start_time": "2018-05-15T01:04:19.186893Z"
    }
   },
   "outputs": [],
   "source": [
    "coef_to_plot = sorted_by_second[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:20.471076Z",
     "start_time": "2018-05-15T01:04:20.466881Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(coef_to_plot, columns=['feature','coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:04:44.281728Z",
     "start_time": "2018-05-15T01:04:44.274519Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:36:26.746978Z",
     "start_time": "2018-05-15T01:36:26.398580Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(df.feature, df.coefficient)\n",
    "plt.xticks(rotation='vertical');\n",
    "plt.yticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:33:25.452457Z",
     "start_time": "2018-05-15T01:33:25.107296Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.barh(df.feature, df.coefficient)\n",
    "plt.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the correlation between readmission and the predictive features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:10:51.231205Z",
     "start_time": "2018-05-15T01:10:51.226947Z"
    }
   },
   "outputs": [],
   "source": [
    "list(df.feature.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:14:18.252744Z",
     "start_time": "2018-05-15T01:14:17.920919Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_x = x.copy()[list(df.feature.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:14:18.559347Z",
     "start_time": "2018-05-15T01:14:18.502778Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_x['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:14:19.208216Z",
     "start_time": "2018-05-15T01:14:19.185374Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:14:23.526109Z",
     "start_time": "2018-05-15T01:14:23.495447Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_x.y = sub_x.y.replace('NO',0)\n",
    "sub_x.y = sub_x.y.replace('<30',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T01:17:06.052769Z",
     "start_time": "2018-05-15T01:17:05.255861Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(sub_x)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = sub_x.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T15:53:06.522292Z",
     "start_time": "2018-05-15T15:53:06.487931Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_x = sub_x.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T15:53:17.435002Z",
     "start_time": "2018-05-15T15:53:17.430205Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T15:54:23.736115Z",
     "start_time": "2018-05-15T15:54:23.628093Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sub_x, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T15:56:08.086691Z",
     "start_time": "2018-05-15T15:56:07.897690Z"
    }
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "x_train_undersampled, y_train_undersampled = rus.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T00:01:22.367051Z",
     "start_time": "2018-05-16T00:01:22.360070Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:11:17.491217Z",
     "start_time": "2018-05-15T17:11:12.246368Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=300, min_samples_split=70)\n",
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T00:02:23.846496Z",
     "start_time": "2018-05-16T00:02:23.743682Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle model for predictor app\n",
    "with open('randomforest.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(randomforest, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:48:08.418430Z",
     "start_time": "2018-05-15T17:48:08.168978Z"
    }
   },
   "outputs": [],
   "source": [
    "array = metrics.confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(array, index = ['early_readmitted', 'not'],\n",
    "                  columns = ['early_readmitted', 'not'])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_num = y_test.copy()\n",
    "y_test_num = y_test_num.replace('NO', 0)\n",
    "y_test_num = y_test_num.replace('<30', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:09:07.516372Z",
     "start_time": "2018-05-15T18:09:06.582724Z"
    }
   },
   "outputs": [],
   "source": [
    "model = randomforest\n",
    "\n",
    "y_score = model.predict_proba(x_test)[:, 1]\n",
    "p, r, t = precision_recall_curve(y_test_num, y_score)\n",
    "\n",
    "# adding last threshold of '1' to threshold list\n",
    "t = np.vstack([t.reshape([-1, 1]), 1])\n",
    "\n",
    "plt.plot(t, p)\n",
    "plt.plot(t, r)\n",
    "plt.title('Precision Recall Curve')\n",
    "# yellow = recall\n",
    "# blue = precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:40:51.578774Z",
     "start_time": "2018-05-15T18:40:51.574552Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:47:52.023044Z",
     "start_time": "2018-05-15T18:47:52.013352Z"
    }
   },
   "outputs": [],
   "source": [
    "thresholding = pd.y_pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:47:41.635695Z",
     "start_time": "2018-05-15T18:47:41.626396Z"
    }
   },
   "outputs": [],
   "source": [
    "thresholding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:47:20.159786Z",
     "start_time": "2018-05-15T18:47:20.149754Z"
    }
   },
   "outputs": [],
   "source": [
    "thresholding['y_test'] = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T19:13:15.587485Z",
     "start_time": "2018-05-15T19:13:14.737528Z"
    }
   },
   "outputs": [],
   "source": [
    "# alternatively, i could have thresholds as columns in a dataframe \n",
    "# with y_test and y_pred as the first two columns\n",
    "# and then calculate the false positive and false negative numbers per column\n",
    "\n",
    "costs = []\n",
    "\n",
    "for t in np.arange(0,1,0.1):\n",
    "    y_pred = [int(1) if i > t else int(0) for i in model.predict_proba(x_test)[:, 1]]\n",
    "    FP = [int(1) if y_pred[i]==1 and y_test_num[i]==0 else int(0) for i in range(len(y_pred)) ]\n",
    "    TP = [int(1) if y_pred[i]==1 and y_test_num[i]==1 else int(0) for i in range(len(y_pred)) ]\n",
    "    FN = [int(1) if y_pred[i]==0 and y_test_num[i]==1 else int(0) for i in range(len(y_pred)) ]\n",
    "    TN = [int(1) if y_pred[i]==0 and y_test_num[i]==0 else int(0) for i in range(len(y_pred)) ]\n",
    "\n",
    "    FPsum = FP.sum()\n",
    "    TPsum = TP.sum()\n",
    "    FNsum = FN.sum()\n",
    "    TNsum = TN.sum()   \n",
    "    \n",
    "    cost = FPsum*304 + TPsum*(304-1246) + FNsum*1246\n",
    "\n",
    "    costs.append(cost)\n",
    "\n",
    "print(costs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:07:56.922795Z",
     "start_time": "2018-05-15T21:06:53.399165Z"
    }
   },
   "outputs": [],
   "source": [
    "y_proba = model.predict_proba(x_test)\n",
    "prec_log = {}\n",
    "rec_log = {}\n",
    "acc_log = {}\n",
    "cost_ben_log = {}\n",
    "\n",
    "for readmit_cost in range(300, 3300, 300):\n",
    "    for i in np.arange(0,1,.01):\n",
    "        i = np.round(i,2)\n",
    "        y_pred_high_precision = y_proba[:,1] >= i \n",
    "        y_pred_high_precision\n",
    "        conf = metrics.confusion_matrix(y_test_num,y_pred_high_precision)\n",
    "\n",
    "        ac_log = round(metrics.accuracy_score(y_test_num,y_pred_high_precision),4)\n",
    "        pc_log = (conf[1, 1] / (conf[1, 1] + conf[0, 1]))\n",
    "        rc_log = (conf[1, 1] / (conf[1, 1] + conf[1, 0]))\n",
    "\n",
    "        acc_log[i]= ac_log\n",
    "        prec_log[i]= pc_log\n",
    "        rec_log[i] = rc_log\n",
    "\n",
    "        FPsum = conf[0, 1]\n",
    "        TPsum = conf[0, 0]\n",
    "        FNsum = conf[1, 0]\n",
    "        TNsum = conf[1, 1]\n",
    "\n",
    "        #cost_ben_log[i] = FPsum*304 + TPsum*(304-1246) + FNsum*1246\n",
    "        #day_cost = 304\n",
    "        #readmit_cost = 1246\n",
    "        day_cost = 300\n",
    "        #readmit_cost = 2500\n",
    "        cost_ben_log[i] = (FPsum*day_cost + TPsum*(day_cost-readmit_cost) + FNsum*(readmit_cost))/len(y_test_num)\n",
    "        # FP = stay in hospital, but didn't need to, costs $304/day\n",
    "        # TP = stay in hospital and needed to, costs $304/day but saves $1246\n",
    "        # FN = readmitted, but should have stayed in hospital, saved $304, but costed $1246\n",
    "        # TN = left hospital, not readmitted, no cost\n",
    "\n",
    "        # metrics.\n",
    "        # TN  # FP\n",
    "        # FN  # TP\n",
    "\n",
    "        #print(min(cost_ben_log.values()))\n",
    "\n",
    "    zipped = zip(cost_ben_log.keys(), cost_ben_log.values())\n",
    "    print(sorted(zipped, key=lambda x: x[0]))\n",
    "\n",
    "    plt.plot(cost_ben_log.keys(),cost_ben_log.values(),label=readmit_cost)\n",
    "    plt.legend();\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Cost ($)\")\n",
    "    plt.grid()\n",
    "    plt.title('Cost per Intervention - Random Forest')\n",
    "    plt.savefig(\"Cost_PerIntervention_Random_Forest\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:58:28.482058Z",
     "start_time": "2018-05-15T20:58:21.832708Z"
    }
   },
   "outputs": [],
   "source": [
    "y_proba = model.predict_proba(x_test)\n",
    "prec_log = {}\n",
    "rec_log = {}\n",
    "acc_log = {}\n",
    "cost_ben_log = {}\n",
    "\n",
    "for i in np.arange(0,1,.01):\n",
    "    i = np.round(i,2)\n",
    "    y_pred_high_precision = y_proba[:,1] >= i \n",
    "    y_pred_high_precision\n",
    "    conf = metrics.confusion_matrix(y_test_num,y_pred_high_precision)\n",
    "    \n",
    "    ac_log = round(metrics.accuracy_score(y_test_num,y_pred_high_precision),4)\n",
    "    pc_log = (conf[1, 1] / (conf[1, 1] + conf[0, 1]))\n",
    "    rc_log = (conf[1, 1] / (conf[1, 1] + conf[1, 0]))\n",
    "    \n",
    "    acc_log[i]= ac_log\n",
    "    prec_log[i]= pc_log\n",
    "    rec_log[i] = rc_log\n",
    "        \n",
    "    FPsum = conf[0, 1]\n",
    "    TPsum = conf[0, 0]\n",
    "    FNsum = conf[1, 0]\n",
    "    TNsum = conf[1, 1]\n",
    "    \n",
    "    #cost_ben_log[i] = FPsum*304 + TPsum*(304-1246) + FNsum*1246\n",
    "    #day_cost = 304\n",
    "    #readmit_cost = 1246\n",
    "    day_cost = 304\n",
    "    readmit_cost = 1246\n",
    "    cost_ben_log[i] = (FPsum*day_cost + TPsum*(day_cost-readmit_cost) + FNsum*(readmit_cost))/len(y_test_num)\n",
    "    # FP = stay in hospital, but didn't need to, costs $304/day\n",
    "    # TP = stay in hospital and needed to, costs $304/day but saves $1246\n",
    "    # FN = readmitted, but should have stayed in hospital, saved $304, but costed $1246\n",
    "    # TN = left hospital, not readmitted, no cost\n",
    "            \n",
    "print(conf)\n",
    "plt.plot(acc_log.keys(),acc_log.values(),label=\"Accuracy\")\n",
    "plt.plot(rec_log.keys(),rec_log.values(),label=\"Recall\")\n",
    "plt.plot(prec_log.keys(),prec_log.values(),label=\"Precision\")\n",
    "# plt.plot(cost_ben.keys(),cost_ben.values(),label=\"Cost Benefit\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Precision / Recall / Accuracy\")\n",
    "plt.title('Precision / Recall / Accuracy curve');\n",
    "plt.axvline(x=0.49, linestyle = '--', linewidth=0.5, color='r')\n",
    "plt.axhline(y=0.42, linestyle = '--', linewidth=0.5, color='r')\n",
    "\n",
    "# metrics.\n",
    "# TN  # FP\n",
    "# FN  # TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T20:58:33.260914Z",
     "start_time": "2018-05-15T20:58:33.115155Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(min(cost_ben_log.values()))\n",
    "\n",
    "zipped = zip(cost_ben_log.keys(), cost_ben_log.values())\n",
    "print(sorted(zipped, key=lambda x: x[0]))\n",
    "\n",
    "plt.plot(cost_ben_log.keys(),cost_ben_log.values(),label=\"Cost\")\n",
    "plt.legend();\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Cost ($)\")\n",
    "plt.grid()\n",
    "plt.title('Cost per Intervention - Random Forest')\n",
    "plt.savefig(\"Cost_PerIntervention_Random_Forest\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.01,1.01,0.05):\n",
    "    y_pred_high_precision = y_proba[:,1] >= i \n",
    "    y_pred_high_precision\n",
    "    conf = metrics.confusion_matrix(y_test,y_pred_high_precision)\n",
    "    print(f\"Threshold at {round(i,2)} \\n\")\n",
    "    print(conf)\n",
    "    print(\"\")\n",
    "    test_thresh = np.round(i,2)\n",
    "    print(f\"Threshold: {test_thresh}\")\n",
    "    print(f\"Accuracy: {acc_log[test_thresh]}\")\n",
    "    print(f\"Precision: {prec_log[test_thresh]}\")\n",
    "    print(f\"Recall: {rec_log[test_thresh]}\")\n",
    "    print(f\"Cost-Benefit: {cost_ben_log[test_thresh]}\" )\n",
    "    print(\"********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:40:42.894696Z",
     "start_time": "2018-05-15T17:40:42.729218Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(y_test, y_pred)\n",
    "confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T17:37:50.837256Z",
     "start_time": "2018-05-15T17:37:50.600038Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['early_readmitted', 'not']\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.imshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T16:14:44.204844Z",
     "start_time": "2018-05-15T16:14:44.197991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T16:17:14.782921Z",
     "start_time": "2018-05-15T16:14:44.382468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters\n",
    "\n",
    "# using x-num fold cross validation\n",
    "cv_num = 3\n",
    "\n",
    "# search across x-num different combinations\n",
    "n_iter_num = 20\n",
    "\n",
    "# and use all available cores\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                               n_iter=n_iter_num, cv=cv_num, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train_undersampled, y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T16:18:00.706899Z",
     "start_time": "2018-05-15T16:18:00.702535Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T16:19:29.625903Z",
     "start_time": "2018-05-15T16:19:29.621011Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=70, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=100,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T16:19:50.107043Z",
     "start_time": "2018-05-15T16:19:34.843250Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest.fit(x_train_undersampled, y_train_undersampled)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T15:56:09.172775Z",
     "start_time": "2018-05-10T15:56:09.168125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-10T15:56:09.725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters\n",
    "\n",
    "# using x-num fold cross validation\n",
    "cv_num = 3\n",
    "\n",
    "# search across 100 different combinations\n",
    "n_iter_num = 20\n",
    "\n",
    "# and use all available cores\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                               n_iter=n_iter_num, cv=cv_num, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the baseline/benchmark model perform?\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(train_features, train_labels)\n",
    "base_accuracy = evaluate(base_model, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the new model perform?\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much did we improve?\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T15:52:35.357543Z",
     "start_time": "2018-05-15T15:51:32.098058Z"
    }
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=70, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "randomforest.fit(x_train, y_train)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=70, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "randomforest.fit(x_train, y_train)\n",
    "randomforest.score(x_test, y_test)\n",
    "y_pred = randomforest.predict(x_test)\n",
    "print(\"Accuracy: %.3f\"% metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
